{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547b8b0d-7e41-4795-ac9d-ccd099026e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/beeno/Dropbox/research_project/pycharm/incremental_vault\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beeno/anaconda3/envs/heexpand/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/beeno/Dropbox/research_project/pycharm/incremental_vault_gpu\n",
    "from Vault.vault import *\n",
    "from multiprocessing import Process, Manager\n",
    "from time import time, sleep\n",
    "from MSPM.mspm_config import *\n",
    "from MSPM.incre_pw_coding import Incremental_Encoder\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eda1040-b97d-4303-8e47-edf070272cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-10 19:52:37,215.215]     configure.py Line  29 __init__():\t Constructor started for '4-gram'\n",
      "[2022-10-10 19:52:37,216.216] ngram_creator.py Line  30 __init__():\t Constructor started for 'NGramCreator, Session: Development, Length: 6, Progress bar: True'\n",
      "[2022-10-10 19:52:37,216.216] ngram_creator.py Line  39 __init__():\t Used alphabet:  !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
      "[2022-10-10 19:52:37,216.216] ngram_creator.py Line  41 __init__():\t Model string length: 1\n",
      "[2022-10-10 19:52:37,216.216] ngram_creator.py Line  46 __init__():\t NGram size: 4\n",
      "[2022-10-10 19:52:37,219.219] ngram_creator.py Line  58 __init__():\t len(IP) theo: 857375\n",
      "[2022-10-10 19:52:37,219.219] ngram_creator.py Line  59 __init__():\t len(CP) theo: 81450625 => 857375 * 95\n",
      "[2022-10-10 19:52:37,219.219] ngram_creator.py Line  62 __init__():\t len(EP) theo: 857375\n",
      "[2022-10-10 19:52:37,840.840] ngram_creator.py Line 308 load():\t Done! Everything loaded from disk.\n",
      "[2022-10-10 19:52:37,840.840] ngram_creator.py Line 309 load():\t Loading the data from disk took: 0:00:00.620598\n",
      "[2022-10-10 19:53:18,072.072] ngram_creator.py Line 308 load():\t Done! Everything loaded from disk.\n",
      "[2022-10-10 19:53:18,072.072] ngram_creator.py Line 309 load():\t Loading the data from disk took: 0:00:40.232304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single password model loading done ...\n",
      "single similar password model loading done ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-10 19:53:18,675.675] ngram_creator.py Line 308 load():\t Done! Everything loaded from disk.\n",
      "[2022-10-10 19:53:18,675.675] ngram_creator.py Line 309 load():\t Loading the data from disk took: 0:00:00.602679\n"
     ]
    }
   ],
   "source": [
    "incre_encoder = Incremental_Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d082704-a559-420b-aa53-d5c5f59f3306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 1/1\n",
      "using 2/2\n",
      "using 1/3\n",
      "using 2/4\n",
      "using 3/5\n",
      "using 4/6\n",
      "using 7/7\n",
      "using 7/8\n",
      "using 9/9\n",
      "using 9/10\n",
      "using 9/11\n",
      "using 8/12\n",
      "using 4/13\n",
      "using 9/14\n",
      "using 1/15\n",
      "using 16/16\n",
      "reals =>  ['jorge19', 'Jorge19', 'venezuela', 'jorge', 'Jorge20', 'venezuela', 'venezuela', 'venezuela', 'venezuela', 'venezuela', 'venezuela', 'venezuela', 'venezuela', 'venezuela1', 'dominican1', 'dominican1']\n",
      "decoys =>  ['polskatha', 'gonzannetali', 'haretskipp', 'arshadowssan', '1234567891', 'lillsmil', 'haretskipp', 'gonzannetali', 'jessed2', 'jessed2', 'gonzannetali', 'gonzannetali', 'polskatha', 'gonzannetali', 'jdpolskath', 'elsey1010']\n"
     ]
    }
   ],
   "source": [
    "vault = {}\n",
    "flst = os.listdir(SOURCE_PATH + '/data/pastebin/fold5')\n",
    "for fname in flst:\n",
    "    f = open(os.path.join(SOURCE_PATH + '/data/pastebin/fold5', fname))\n",
    "    vault.update(json.load(f))\n",
    "i = 0\n",
    "for vault_id in vault:\n",
    "    conca = []\n",
    "    i = i + 1\n",
    "    if i > 1:\n",
    "        break\n",
    "    mpw_en = getline(SOURCE_PATH + \"/data/password_dict.txt\", random.randint(1, DICT_SIZE)).strip()\n",
    "    ciphers, l = incre_encoder.encode_encrypt(vault[vault_id], mpw_en)\n",
    "    while True:\n",
    "        mpw = getline(SOURCE_PATH + \"/data/password_dict.txt\", random.randint(1, DICT_SIZE)).strip()\n",
    "        if mpw != mpw_en:\n",
    "            break\n",
    "    decoy_set = incre_encoder.decrypt_decode(ciphers, mpw, l)\n",
    "    print('reals => ', vault[vault_id])\n",
    "    print('decoys => ', decoy_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb6a9b-e76b-4be8-8282-c670f0ee94d1",
   "metadata": {},
   "source": [
    "# calculating alpha for sspm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09276e3f-ee1a-4ac0-9cf2-07bc16228ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655c7a70-e30e-43b5-bf3d-745e7b6255dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test file: fold_5.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3134908576914774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = PASTB_PATH\n",
    "train_vault = {}\n",
    "flst = os.listdir(data_path)\n",
    "for fname in flst:\n",
    "    if str(TEST_FOLD) in fname:\n",
    "        print('test file:', fname)\n",
    "        #continue # comment the code for training all\n",
    "    f = open(os.path.join(data_path, fname))\n",
    "    train_vault.update(json.load(f))\n",
    "\n",
    "alphas = []\n",
    "for vault_id in train_vault:\n",
    "    avault = train_vault[vault_id]\n",
    "    if len(avault) > 1 and len(avault) < 51:\n",
    "        alphas.append(np.array([math.factorial(count-1) for _, count in \\\n",
    "                                collections.Counter(avault).items() if count > 1]).sum() \\\n",
    "                      / math.factorial(len(avault) - 1))\n",
    "#print(alphas)\n",
    "np.array(alphas).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74c772-aa13-4281-ac2b-fe7162b066f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
